{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b4de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from module.gatedTransformer import GatedTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87c0cd4",
   "metadata": {},
   "source": [
    "### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2adcc4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46601, 5)\n",
      "[1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "file_name = \"1_20131027.pkl\"\n",
    "open_file = open(file_name, \"rb\")\n",
    "seed_data = pickle.load(open_file)\n",
    "open_file.close()\n",
    "\n",
    "data, label = seed_data[1]\n",
    "print(data.shape)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570e6a30",
   "metadata": {},
   "source": [
    "### Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15c4b30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Hz = 200\n",
    "duration = 1\n",
    "size = Hz*duration\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9b73a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_window(series, label, size, batch_size=32, shift=1):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
    "    ds = ds.window(size= size, shift = shift, drop_remainder = True)\n",
    "    ds = ds.flat_map(lambda w: w.batch(size))\n",
    "    ds = ds.map(lambda w: (w, label))\n",
    "    return ds.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "448c2dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "726"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = create_dataset_window(data, label, size, batch_size, int(size/100))\n",
    "len(list(ds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "718efca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_list = []\n",
    "for item in seed_data:\n",
    "    data, label = item\n",
    "    ds = create_dataset_window(data, label, size, int(size/100))\n",
    "    dataset_list.append(ds)\n",
    "\n",
    "stack_dataset = dataset_list[0]\n",
    "# for dataset in dataset_list[1:]:\n",
    "#     stack_dataset = stack_dataset.concatenate(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fce7fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_SIZE = 100\n",
    "train_size = int(0.9 * DATASET_SIZE)\n",
    "val_size = int(0.05 * DATASET_SIZE)\n",
    "test_size = int(0.05 * DATASET_SIZE)\n",
    "\n",
    "stack_dataset = stack_dataset.shuffle(DATASET_SIZE)\n",
    "train_dataset = stack_dataset.take(train_size).prefetch(100).repeat()\n",
    "test_dataset = stack_dataset.skip(train_size).prefetch(100)\n",
    "val_dataset = test_dataset.take(val_size).prefetch(100)\n",
    "test_dataset = test_dataset.skip(val_size).prefetch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "438aa98e",
   "metadata": {},
   "outputs": [],
   "source": [
    " num_layers = 8\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "dff = 1024\n",
    "\n",
    "target_size = 3\n",
    "model = GatedTransformer(num_layers, d_model, num_heads, dff, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81d905fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.CategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2f345fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, x, y, training):\n",
    "  # training=training is needed only if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "    y_ = model(x, training=training)\n",
    "\n",
    "    return loss_object(y_true=y, y_pred=y_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59219b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss(model, inputs, targets, training=True)\n",
    "    return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d72008ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17d9bb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss: 1.155, Accuracy: 100.000%\n",
      "Epoch 001: Loss: 0.002, Accuracy: 100.000%\n",
      "Epoch 002: Loss: 0.000, Accuracy: 100.000%\n"
     ]
    }
   ],
   "source": [
    "## Note: Rerunning this cell uses the same model variables\n",
    "\n",
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "    epoch_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "    # Training loop - using batches of 32\n",
    "    for x, y in train_dataset.take(1):\n",
    "    # Optimize the model\n",
    "        loss_value, grads = grad(model, x, y)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        # Track progress\n",
    "        epoch_loss_avg.update_state(loss_value)  # Add current batch loss\n",
    "        # Compare predicted label to actual label\n",
    "        # training=True is needed only if there are layers with different\n",
    "        # behavior during training versus inference (e.g. Dropout).\n",
    "        epoch_accuracy.update_state(y, model(x, training=True))\n",
    "\n",
    "        # End epoch\n",
    "        train_loss_results.append(epoch_loss_avg.result())\n",
    "        train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "   \n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                                epoch_loss_avg.result(),\n",
    "                                                                epoch_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321d44b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab7bd9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
